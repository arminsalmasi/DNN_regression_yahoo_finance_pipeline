{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yfmf import *\n",
    "import os\n",
    "from os import walk\n",
    "from os import path\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sympy as sym\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as scp\n",
    "from math import erf\n",
    "import yfinance as yf\n",
    "import collections\n",
    "import pandas as pd\n",
    "from pandas_datareader import data as pdr\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from itertools import cycle, islice\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import mplfinance as mpf\n",
    "import copy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for (dirpath, dirnames, filenames) in walk(\"data\\\\\"):\n",
    "    f.extend(filenames)\n",
    "    break\n",
    "tickers= [x.replace('.csv', '') for x in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''read data from csv file'''\n",
    "dfs={}\n",
    "dates_pdtimestamp={}\n",
    "date_index_str_split={}\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        path.exists(\"data\\\\\"+ticker+\".csv\")\n",
    "        dfs[ticker]=pd.read_csv(\"data\\\\\"+ticker+\".csv\",index_col=0,parse_dates=True)\n",
    "        #dfs[ticker].index = dfs[ticker].index.get_level_values(0).astype(int)\n",
    "        #print(dfs[ticker])\n",
    "        years=(pd.DatetimeIndex(dfs[ticker].index).year)\n",
    "        months=(pd.DatetimeIndex(dfs[ticker].index).month)\n",
    "        days=(pd.DatetimeIndex(dfs[ticker].index).day)\n",
    "        time=(pd.DatetimeIndex(dfs[ticker].index).time)\n",
    " \n",
    "        y = pd.get_dummies(years)\n",
    "        y.columns=[str(i) for i in np.unique(years)]\n",
    "        m = pd.get_dummies(months)\n",
    "        m.columns=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "        d = pd.get_dummies( days)\n",
    "        d.columns=['1th', '2th', '3th', '4th', '5th', '6th', '7th', '8th', '9th', '10th', '11th', '12th', '13th', '14th', '15th', '16th', '17th', '18th', '19th', '20th', '21th', '22th', '23th', '24th', '25th', '26th', '27th', '28th', '29th', '30th','31th']\n",
    "        date=y.append(m).append(d)\n",
    "        dfs[ticker]=dfs[ticker].append(date)\n",
    "        dfs[ticker].index=np.arange(0,len(dfs[ticker]),1)\n",
    "        print(dfs[ticker].head)\n",
    "    except OSError as e:\n",
    "         print(\"Error: %s : %s\" % (\"data\\\\\"+ticker+\".csv\", e.strerror))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''read data from csv file'''\n",
    "dfs={}\n",
    "dates_pdtimestamp={}\n",
    "date_index_str_split={}\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        path.exists(\"data\\\\\"+ticker+\".csv\")\n",
    "        dfs[ticker]=pd.read_csv(\"data\\\\\"+ticker+\".csv\",index_col=0,parse_dates=True)\n",
    "        dates_pdtimestamp[ticker]=dfs[ticker].index\n",
    "        date_index_str=(dfs[ticker].index.astype(str))\n",
    "        splits=[]\n",
    "        for string in date_index_str:\n",
    "            splits.append(string.split('-'))\n",
    "        Y,D,M=[],[],[]\n",
    "        for split in splits:\n",
    "            Y.append(int(split[0]))\n",
    "            M.append(int(split[1]))\n",
    "            D.append(int(split[2]))\n",
    "        dfs[ticker]['Y'],dfs[ticker]['M'],dfs[ticker]['D']=Y,M,D\n",
    "        dfs[ticker].index=np.arange(0,len(dfs[ticker]),1)\n",
    "    except OSError as e:\n",
    "        print(\"Error: %s : %s\" % (\"data\\\\\"+ticker+\".csv\", e.strerror))\n",
    "dfs['aapl'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''plot'''\n",
    "lim1=0\n",
    "lim2=-1\n",
    "means=()\n",
    "for ticker in tickers:\n",
    "    data = pd.read_csv(\"data\\\\\"+ticker+\".csv\",index_col=0,parse_dates=True)\n",
    "    plot_stocks(data,lim1,lim2,means,ticker,frmaesize=(5,3),show_nonetrading=False,show_volume=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''scale values'''\n",
    "target={}\n",
    "dfs_sc= copy.deepcopy(dfs)\n",
    "for ticker in tickers:\n",
    "    for col in dfs[ticker].keys():\n",
    "        if col!='D' and col!='Y' and col!='M' and col!='Adj Close':\n",
    "            dfs_sc[ticker][col] = MinMaxScaler().fit_transform(dfs_sc[ticker][[col]])\n",
    "    #plot_features(dfs[ticker],dfs_sc[ticker])\n",
    "    target[ticker]= dfs_sc[ticker].pop('Adj Close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''slice trainsets'''\n",
    "train_sets={}\n",
    "dev_sets={}\n",
    "test_sets={}\n",
    "train,dev,test,ltrain,ldev,ltest =split_data(dfs_sc['ibm'],target['ibm'],0.9,0.05)\n",
    "train_shuffle= train.shuffle(ltrain).batch(2**8)\n",
    "dev_shuffle= dev.shuffle(ldev).batch(16)\n",
    "test_shuffle= test.shuffle(ltest).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elements,_ in train_shuffle.take(1):  # only take first element of dataset\n",
    "    numpy_elements = elements.numpy()\n",
    "    input_size = (numpy_elements.size)\n",
    "model = get_compiled_model(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit= model.fit(train_shuffle, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(fit.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(fit.history['accuracy'])\n",
    "#plt.plot(fit.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(fit.history['loss'])\n",
    "#plt.plot(fit.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(dev_shuffle)\n",
    "plt.figure()\n",
    "plt.plot(predictions)\n",
    "plt.figure()\n",
    "plt.plot(target['aapl'][-ldev:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holdDays = 5\n",
    "# totalDays = dfs_concat_scaled_dataframe.shape[0]\n",
    "# #mlpr.fit(dfs_concat_scaled_dataframe.index[0:(totalDays-holdDays)].T, dfs_concat_scaled_dataframe['Adj Close'][0:(totalDays-holdDays)])\n",
    "# mlpr.fit(a, dfs_concat_scaled_dataframe['Adj Close'][0:(totalDays-holdDays)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Predict the stock price using the model\n",
    "# pricePredict = mlpr.predict(date_idx)\n",
    "# #Display the predicted reuslts agains the actual data\n",
    "# plt.plot(date_idx, adj_close_price)\n",
    "# plt.plot(date_idx, pricePredict, c='#5aa9ab')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Number of neurons in the input, output, and hidden layers\n",
    "# input2 = 1\n",
    "# output2 = 1\n",
    "# hidden2 = 50\n",
    "# #array of layers, 3 hidden and 1 output, along with the tanh activation function \n",
    "# layers = [('F', hidden2), ('AF', 'tanh'), ('F', hidden2), ('AF', 'tanh'), ('F', hidden2), ('AF', 'tanh'), ('F', output2)]\n",
    "# #construct the model and dictate params\n",
    "# mlpr2 = ANNR([input2], layers, batchSize = 256, maxIter = 10000, tol = 0.01, reg = 1e-4, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holdDays = 5\n",
    "# totalDays = len(date_idx)\n",
    "# mlpr2.fit(date_idx[0:(totalDays-holdDays)], adj_close_price[0:(totalDays-holdDays)])\n",
    "# pricePredict2 = mlpr2.predict(date_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(date_idx, adj_close_price)\n",
    "# plt.plot(date_idx, pricePredict, c='#5aa9ab')\n",
    "# plt.plot(date_idx, pricePredict2, c='#8B008B')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pricePredict3 = mlpr2.predict(date_idx[-holdDays:])\n",
    "# print((pricePredict3-date_idx[-holdDays:])/date_idx[-holdDays:]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
